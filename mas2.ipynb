{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6b2970f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Optional, Tuple, Literal\n",
        "\n",
        "from supabase import create_client\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "55cc4dca",
      "metadata": {},
      "outputs": [],
      "source": [
        "SortOrder = Literal[\"asc\", \"desc\"]\n",
        "\n",
        "\n",
        "def _clean(s: Optional[str]) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", (s or \"\").strip())\n",
        "\n",
        "\n",
        "def _ilike_pattern(q: str) -> str:\n",
        "    q = _clean(q)\n",
        "    if not q:\n",
        "        return \"%\"\n",
        "    return f\"%{q}%\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a9551996",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "@dataclass\n",
        "class GrablinDB:\n",
        "    \"\"\"Thin wrapper around Supabase queries for acquisition/RAG tooling.\"\"\"\n",
        "    url: str\n",
        "    key: str\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.sb = create_client(self.url, self.key)\n",
        "\n",
        "    # ----------------------------\n",
        "    # WKO: branches\n",
        "    # ----------------------------\n",
        "\n",
        "    def wko_list_branches(self, limit: int = 5000) -> Dict[str, Any]:\n",
        "        \"\"\"Return distinct branch labels + urls.\"\"\"\n",
        "        res = (\n",
        "            self.sb.table(\"wko_branches\")\n",
        "            .select(\"branche,branch_url,letter,discovered_at\")\n",
        "            .limit(limit)\n",
        "            .execute()\n",
        "        )\n",
        "        rows = res.data or []\n",
        "        # Deduplicate by (branche, branch_url)\n",
        "        seen = set()\n",
        "        out = []\n",
        "        for r in rows:\n",
        "            k = (r.get(\"branche\"), r.get(\"branch_url\"))\n",
        "            if k in seen:\n",
        "                continue\n",
        "            seen.add(k)\n",
        "            out.append(r)\n",
        "        return {\"rows\": out, \"count\": len(out)}\n",
        "\n",
        "    def wko_match_branch(self, query: str, limit: int = 10) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Fuzzy-ish branch lookup using ilike on branche.\n",
        "        If you later add a pg_trgm RPC, swap this to sb.rpc('match_wko_branch', ...).\n",
        "        \"\"\"\n",
        "        q = _clean(query)\n",
        "        if not q:\n",
        "            return {\"candidates\": []}\n",
        "\n",
        "        res = (\n",
        "            self.sb.table(\"wko_branches\")\n",
        "            .select(\"branche,branch_url,letter\")\n",
        "            .ilike(\"branche\", _ilike_pattern(q))\n",
        "            .limit(limit)\n",
        "            .execute()\n",
        "        )\n",
        "        return {\"candidates\": res.data or [], \"query\": q}\n",
        "\n",
        "    # ----------------------------\n",
        "    # WKO: companies\n",
        "    # ----------------------------\n",
        "\n",
        "    def wko_companies_by_branch(\n",
        "        self,\n",
        "        branche: str,\n",
        "        limit: int = 25,\n",
        "        offset: int = 0,\n",
        "        order_by: str = \"crawled_at\",\n",
        "        order: SortOrder = \"desc\",\n",
        "        only_with_email: bool = False,\n",
        "        only_with_website: bool = False,\n",
        "    ) -> Dict[str, Any]:\n",
        "        q = (\n",
        "            self.sb.table(\"wko_companies\")\n",
        "            .select(\"name,branche,address,zip_city,street,email,phone,company_website,wko_detail_url,crawled_at,source_list_url\")\n",
        "            .eq(\"branche\", branche)\n",
        "        )\n",
        "        if only_with_email:\n",
        "            q = q.not_.is_(\"email\", \"null\")\n",
        "        if only_with_website:\n",
        "            q = q.not_.is_(\"company_website\", \"null\")\n",
        "\n",
        "        q = q.order(order_by, desc=(order == \"desc\")).range(offset, offset + limit - 1)\n",
        "        res = q.execute()\n",
        "        rows = res.data or []\n",
        "        return {\n",
        "            \"rows\": rows,\n",
        "            \"count\": len(rows),\n",
        "            \"branche\": branche,\n",
        "            \"limit\": limit,\n",
        "            \"offset\": offset,\n",
        "            \"filters\": {\"only_with_email\": only_with_email, \"only_with_website\": only_with_website},\n",
        "        }\n",
        "\n",
        "    def wko_search_companies(\n",
        "        self,\n",
        "        text: str,\n",
        "        limit: int = 25,\n",
        "        offset: int = 0,\n",
        "        branche: Optional[str] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Keyword search using search_text (exists for fuzzy matching).\n",
        "        \"\"\"\n",
        "        t = _clean(text)\n",
        "        if not t:\n",
        "            return {\"rows\": [], \"count\": 0, \"query\": \"\"}\n",
        "\n",
        "        q = (\n",
        "            self.sb.table(\"wko_companies\")\n",
        "            .select(\"name,branche,address,email,phone,company_website,wko_detail_url,crawled_at\")\n",
        "            .ilike(\"search_text\", _ilike_pattern(t))\n",
        "        )\n",
        "        if branche:\n",
        "            q = q.eq(\"branche\", branche)\n",
        "\n",
        "        q = q.order(\"crawled_at\", desc=True).range(offset, offset + limit - 1)\n",
        "        res = q.execute()\n",
        "        return {\"rows\": res.data or [], \"count\": len(res.data or []), \"query\": t, \"branche\": branche}\n",
        "\n",
        "    def wko_sample_companies(\n",
        "        self,\n",
        "        branche: Optional[str] = None,\n",
        "        sample_n: int = 10,\n",
        "        fetch_pool: int = 200,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Cheap sampling: fetch a recent pool and randomly sample.\n",
        "        (True DB-side random sampling is better via SQL/RPC, but this is easiest.)\n",
        "        \"\"\"\n",
        "        q = (\n",
        "            self.sb.table(\"wko_companies\")\n",
        "            .select(\"name,branche,address,email,phone,company_website,wko_detail_url,crawled_at\")\n",
        "            .order(\"crawled_at\", desc=True)\n",
        "            .limit(fetch_pool)\n",
        "        )\n",
        "        if branche:\n",
        "            q = q.eq(\"branche\", branche)\n",
        "\n",
        "        res = q.execute()\n",
        "        rows = res.data or []\n",
        "        if not rows:\n",
        "            return {\"rows\": [], \"count\": 0, \"branche\": branche}\n",
        "\n",
        "        sample_n = min(sample_n, len(rows))\n",
        "        sampled = random.sample(rows, sample_n)\n",
        "        return {\"rows\": sampled, \"count\": len(sampled), \"branche\": branche, \"pool\": len(rows)}\n",
        "\n",
        "    def wko_count_by_branch(self, limit: int = 50) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Returns top branches by frequency (client-side aggregation for MVP).\n",
        "        For larger scale, implement as SQL/RPC.\n",
        "        \"\"\"\n",
        "        res = self.sb.table(\"wko_companies\").select(\"branche\").limit(5000).execute()\n",
        "        rows = res.data or []\n",
        "        counts: Dict[str, int] = {}\n",
        "        for r in rows:\n",
        "            b = r.get(\"branche\") or \"\"\n",
        "            if not b:\n",
        "                continue\n",
        "            counts[b] = counts.get(b, 0) + 1\n",
        "        top = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)[:limit]\n",
        "        return {\"top\": [{\"branche\": b, \"count\": c} for b, c in top], \"scanned\": len(rows)}\n",
        "\n",
        "    # ----------------------------\n",
        "    # Projectfacts\n",
        "    # ----------------------------\n",
        "\n",
        "    def pf_search(\n",
        "        self,\n",
        "        text: str,\n",
        "        limit: int = 25,\n",
        "        offset: int = 0,\n",
        "        city: Optional[str] = None,\n",
        "        industry: Optional[str] = None,\n",
        "        size: Optional[str] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        t = _clean(text)\n",
        "        if not t and not (city or industry or size):\n",
        "            return {\"rows\": [], \"count\": 0}\n",
        "\n",
        "        q = self.sb.table(\"projectfacts\").select(\n",
        "            \"name,company_address,city,state,country,industries,size,last_activity_at,last_changed_at\"\n",
        "        )\n",
        "        if t:\n",
        "            q = q.ilike(\"search_text\", _ilike_pattern(t))\n",
        "        if city:\n",
        "            q = q.ilike(\"city\", _ilike_pattern(city))\n",
        "        if industry:\n",
        "            q = q.ilike(\"industries\", _ilike_pattern(industry))\n",
        "        if size:\n",
        "            q = q.ilike(\"size\", _ilike_pattern(size))\n",
        "\n",
        "        q = q.order(\"last_activity_at\", desc=True).range(offset, offset + limit - 1)\n",
        "        res = q.execute()\n",
        "        return {\"rows\": res.data or [], \"count\": len(res.data or []), \"filters\": {\"city\": city, \"industry\": industry, \"size\": size}}\n",
        "\n",
        "    # ----------------------------\n",
        "    # EVI Bilanz publications\n",
        "    # ----------------------------\n",
        "\n",
        "    def evi_search_publications(\n",
        "        self,\n",
        "        text: str,\n",
        "        limit: int = 25,\n",
        "        offset: int = 0,\n",
        "        date_from: Optional[str] = None,  # YYYY-MM-DD\n",
        "        date_to: Optional[str] = None,    # YYYY-MM-DD\n",
        "        company_name: Optional[str] = None,\n",
        "        firmenbuchnummer: Optional[str] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Searches EVI publication events.\n",
        "        Uses trigram-indexed text columns via ilike (MVP).\n",
        "        \"\"\"\n",
        "        t = _clean(text)\n",
        "        q = self.sb.table(\"evi_bilanz_publications\").select(\n",
        "            \"publication_date,publication_type,company_name,firmenbuchnummer,detail_url,source_search_url,crawled_at\"\n",
        "        )\n",
        "\n",
        "        if t:\n",
        "            q = q.ilike(\"search_text\", _ilike_pattern(t))\n",
        "        if company_name:\n",
        "            q = q.ilike(\"company_name\", _ilike_pattern(company_name))\n",
        "        if firmenbuchnummer:\n",
        "            q = q.eq(\"firmenbuchnummer\", _clean(firmenbuchnummer))\n",
        "        if date_from:\n",
        "            q = q.gte(\"publication_date\", date_from)\n",
        "        if date_to:\n",
        "            q = q.lte(\"publication_date\", date_to)\n",
        "\n",
        "        q = q.order(\"publication_date\", desc=True).range(offset, offset + limit - 1)\n",
        "        res = q.execute()\n",
        "        return {\n",
        "            \"rows\": res.data or [],\n",
        "            \"count\": len(res.data or []),\n",
        "            \"filters\": {\"date_from\": date_from, \"date_to\": date_to, \"company_name\": company_name, \"firmenbuchnummer\": firmenbuchnummer},\n",
        "        }\n",
        "\n",
        "    def evi_recent_publications(self, days: int = 30, limit: int = 50) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Convenience wrapper: relies on publication_date; compute date range client-side if you want.\n",
        "        For MVP, just return latest by date.\n",
        "        \"\"\"\n",
        "        res = (\n",
        "            self.sb.table(\"evi_bilanz_publications\")\n",
        "            .select(\"publication_date,publication_type,company_name,firmenbuchnummer,detail_url\")\n",
        "            .order(\"publication_date\", desc=True)\n",
        "            .limit(limit)\n",
        "            .execute()\n",
        "        )\n",
        "        return {\"rows\": res.data or [], \"count\": len(res.data or [])}\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Helper: build from .env\n",
        "# ----------------------------\n",
        "\n",
        "def grablin_db_from_env(use_service_role: bool = True) -> GrablinDB:\n",
        "    load_dotenv()\n",
        "    url = os.getenv(\"SUPABASE_URL\")\n",
        "    key = os.getenv(\"SUPABASE_SERVICE_ROLE_KEY\" if use_service_role else \"SUPABASE_ANON_KEY\")\n",
        "    if not url or not key:\n",
        "        raise RuntimeError(\"Missing SUPABASE_URL or SUPABASE_*_KEY in env\")\n",
        "    return GrablinDB(url=url, key=key)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Tool registry for an agent\n",
        "# ----------------------------\n",
        "\n",
        "def grablin_tools(db: GrablinDB) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Return callables that can be handed to DSPy (or any agent runner).\n",
        "    \"\"\"\n",
        "    return {\n",
        "        # WKO\n",
        "        \"wko_list_branches\": db.wko_list_branches,\n",
        "        \"wko_match_branch\": db.wko_match_branch,\n",
        "        \"wko_companies_by_branch\": db.wko_companies_by_branch,\n",
        "        \"wko_search_companies\": db.wko_search_companies,\n",
        "        \"wko_sample_companies\": db.wko_sample_companies,\n",
        "        \"wko_count_by_branch\": db.wko_count_by_branch,\n",
        "        # Projectfacts\n",
        "        \"pf_search\": db.pf_search,\n",
        "        # EVI\n",
        "        \"evi_search_publications\": db.evi_search_publications,\n",
        "        \"evi_recent_publications\": db.evi_recent_publications,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eca6323",
      "metadata": {},
      "outputs": [],
      "source": [
        "GRABLIN_TOOL_SPECS = [\n",
        "  {\n",
        "    \"name\": \"wko_list_branches\",\n",
        "    \"description\": \"List known WKO branch labels and URLs from wko_branches. Use to discover valid branch names.\",\n",
        "    \"args\": {\"limit\": \"int (default 5000)\"},\n",
        "    \"returns\": \"dict: {rows: [{branche, branch_url, letter, discovered_at}], count: int}\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"wko_match_branch\",\n",
        "    \"description\": \"Fuzzy match a user-provided branch phrase to known WKO branches. Use before querying companies by branch.\",\n",
        "    \"args\": {\"query\": \"str\", \"limit\": \"int (default 10)\"},\n",
        "    \"returns\": \"dict: {candidates: [{branche, branch_url, letter}], query: str}\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"wko_companies_by_branch\",\n",
        "    \"description\": \"Get companies for an exact WKO branche label. Use after choosing a branche from wko_match_branch.\",\n",
        "    \"args\": {\n",
        "      \"branche\": \"str (required)\",\n",
        "      \"limit\": \"int (default 25, max 50 recommended)\",\n",
        "      \"offset\": \"int (default 0)\",\n",
        "      \"order_by\": \"str (default crawled_at)\",\n",
        "      \"order\": \"asc|desc (default desc)\",\n",
        "      \"only_with_email\": \"bool (default False)\",\n",
        "      \"only_with_website\": \"bool (default False)\"\n",
        "    },\n",
        "    \"returns\": \"dict: {rows: [company], count: int, branche: str, limit: int, offset: int, filters: {...}}\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"wko_search_companies\",\n",
        "    \"description\": \"Keyword search companies by search_text (name/address/branche/etc). Use if the branch is unknown or query is by company name.\",\n",
        "    \"args\": {\"text\": \"str\", \"limit\": \"int (default 25)\", \"offset\": \"int (default 0)\", \"branche\": \"str|null\"},\n",
        "    \"returns\": \"dict: {rows: [company], count: int, query: str, branche: str|null}\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"wko_sample_companies\",\n",
        "    \"description\": \"Return a random sample of companies (optionally within a branche) from a recent pool.\",\n",
        "    \"args\": {\"branche\": \"str|null\", \"sample_n\": \"int (default 10)\", \"fetch_pool\": \"int (default 200)\"},\n",
        "    \"returns\": \"dict: {rows: [company], count: int, branche: str|null, pool: int}\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"wko_count_by_branch\",\n",
        "    \"description\": \"Return approximate top branches by number of companies (client-side aggregation over a capped scan). Use for exploration.\",\n",
        "    \"args\": {\"limit\": \"int (default 50)\"},\n",
        "    \"returns\": \"dict: {top: [{branche, count}], scanned: int}\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"pf_search\",\n",
        "    \"description\": \"Search projectfacts for companies with metadata (industries/size/activity). Useful for enrichment and acquisition targeting.\",\n",
        "    \"args\": {\"text\": \"str\", \"limit\": \"int (default 25)\", \"offset\": \"int (default 0)\", \"city\": \"str|null\", \"industry\": \"str|null\", \"size\": \"str|null\"},\n",
        "    \"returns\": \"dict: {rows: [projectfact], count: int, filters: {...}}\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"evi_search_publications\",\n",
        "    \"description\": \"Search EVI bilanz publications by text/company/date/firmenbuchnummer. Use for financial/relevance signals.\",\n",
        "    \"args\": {\"text\": \"str\", \"limit\": \"int (default 25)\", \"offset\": \"int (default 0)\", \"date_from\": \"YYYY-MM-DD|null\", \"date_to\": \"YYYY-MM-DD|null\",\n",
        "             \"company_name\": \"str|null\", \"firmenbuchnummer\": \"str|null\"},\n",
        "    \"returns\": \"dict: {rows: [publication], count: int, filters: {...}}\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"evi_recent_publications\",\n",
        "    \"description\": \"Get latest EVI publications ordered by publication_date. Use for 'recent filings' questions.\",\n",
        "    \"args\": {\"days\": \"int (default 30)\", \"limit\": \"int (default 50)\"},\n",
        "    \"returns\": \"dict: {rows: [publication], count: int}\"\n",
        "  }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54ca2a2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import dspy\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from grablin_tools import grablin_db_from_env, grablin_tools\n",
        "\n",
        "# -----------------------------\n",
        "# Signature (with history)\n",
        "# -----------------------------\n",
        "class Grablin(dspy.Signature):\n",
        "    \"\"\"Grablin is a tool-using acquisition assistant over Supabase company datasets.\n",
        "\n",
        "    Rules:\n",
        "    - Use tools for any factual/company-specific claims.\n",
        "    - Do not invent company details or counts.\n",
        "    - If branch name is unclear, use wko_match_branch first.\n",
        "    \"\"\"\n",
        "\n",
        "    user_request: str = dspy.InputField(desc=\"User message / question.\")\n",
        "    history: dspy.History = dspy.InputField(desc=\"Conversation history.\")\n",
        "    process_result: str = dspy.OutputField(desc=\"Answer grounded in tool outputs; include small lists and next-step questions.\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Tool wrappers (docstrings + type hints are important for ReAct)\n",
        "# -----------------------------\n",
        "def wko_list_branches(limit: int = 5000) -> dict:\n",
        "    \"\"\"List known WKO branches (branche + branch_url). Use to discover valid branch names.\"\"\"\n",
        "    return _TOOLS[\"wko_list_branches\"](limit=limit)\n",
        "\n",
        "def wko_match_branch(query: str, limit: int = 10) -> dict:\n",
        "    \"\"\"Fuzzy match a branch phrase to known WKO branches. Use before querying companies_by_branch.\"\"\"\n",
        "    return _TOOLS[\"wko_match_branch\"](query=query, limit=limit)\n",
        "\n",
        "def search_companies(text: str, limit: int = 25, offset: int = 0, branche: str | None = None) -> dict:\n",
        "    \"\"\"Search WKO companies by text (name/address/branche etc. via search_text). Use when branch is unknown or user gives keywords.\"\"\"\n",
        "    return _TOOLS[\"wko_search_companies\"](text=text, limit=limit, offset=offset, branche=branche)\n",
        "\n",
        "def companies_by_branch(branche: str, limit: int = 25, offset: int = 0, only_with_email: bool = False, only_with_website: bool = False) -> dict:\n",
        "    \"\"\"Get companies for an exact WKO branche label. Use after selecting a branche from wko_match_branch.\"\"\"\n",
        "    return _TOOLS[\"wko_companies_by_branch\"](\n",
        "        branche=branche,\n",
        "        limit=limit,\n",
        "        offset=offset,\n",
        "        only_with_email=only_with_email,\n",
        "        only_with_website=only_with_website,\n",
        "    )\n",
        "\n",
        "def sample_companies(branche: str | None = None, sample_n: int = 10, fetch_pool: int = 200) -> dict:\n",
        "    \"\"\"Return a random sample of WKO companies (optionally restricted to a branche).\"\"\"\n",
        "    return _TOOLS[\"wko_sample_companies\"](branche=branche, sample_n=sample_n, fetch_pool=fetch_pool)\n",
        "\n",
        "def pf_search(text: str, limit: int = 25, offset: int = 0, city: str | None = None, industry: str | None = None, size: str | None = None) -> dict:\n",
        "    \"\"\"Search Projectfacts (company profiles: industries/size/activity). Useful for enrichment and acquisition targeting.\"\"\"\n",
        "    return _TOOLS[\"pf_search\"](text=text, limit=limit, offset=offset, city=city, industry=industry, size=size)\n",
        "\n",
        "def evi_search(text: str, limit: int = 25, offset: int = 0, date_from: str | None = None, date_to: str | None = None,\n",
        "               company_name: str | None = None, firmenbuchnummer: str | None = None) -> dict:\n",
        "    \"\"\"Search EVI bilanz publications (financial/relevance signal) by text/company/date/firmenbuchnummer.\"\"\"\n",
        "    return _TOOLS[\"evi_search_publications\"](\n",
        "        text=text, limit=limit, offset=offset,\n",
        "        date_from=date_from, date_to=date_to,\n",
        "        company_name=company_name, firmenbuchnummer=firmenbuchnummer\n",
        "    )\n",
        "\n",
        "def evi_recent(limit: int = 50) -> dict:\n",
        "    \"\"\"Fetch latest EVI bilanz publication events ordered by publication_date.\"\"\"\n",
        "    return _TOOLS[\"evi_recent_publications\"](limit=limit)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    load_dotenv()\n",
        "\n",
        "    # DSPy LM\n",
        "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "        raise SystemExit(\"Missing OPENAI_API_KEY in env\")\n",
        "    dspy.configure(lm=dspy.LM(\"openai/gpt-5.2\"))\n",
        "\n",
        "    # Supabase tools (service role for server-side agent)\n",
        "    db = grablin_db_from_env(use_service_role=True)\n",
        "    _TOOLS = grablin_tools(db)\n",
        "\n",
        "    # ReAct agent with tools\n",
        "    agent = dspy.ReAct(\n",
        "        Grablin,\n",
        "        tools=[\n",
        "            wko_list_branches,\n",
        "            wko_match_branch,\n",
        "            search_companies,\n",
        "            companies_by_branch,\n",
        "            sample_companies,\n",
        "            pf_search,\n",
        "            evi_search,\n",
        "            evi_recent,\n",
        "        ],\n",
        "        max_iters=12,\n",
        "    )\n",
        "\n",
        "    # Conversation history\n",
        "    history = dspy.History(messages=[])\n",
        "\n",
        "    print(\"Grablin ready. Ask about branches, companies, or EVI bilanz publications.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user = input(\"You: \").strip()\n",
        "        if not user:\n",
        "            continue\n",
        "\n",
        "        # Run agent\n",
        "        out = agent(user_request=user, history=history)\n",
        "\n",
        "        # Update history (keys must match signature fields)\n",
        "        history.messages.append({\"user_request\": user})\n",
        "        history.messages.append({\"process_result\": out.process_result})\n",
        "\n",
        "        print(\"\\nGrablin:\\n\" + out.process_result + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2591a1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Any, Dict, List, Optional, Literal\n",
        "\n",
        "import dspy\n",
        "from dotenv import load_dotenv\n",
        "from supabase import create_client\n",
        "\n",
        "Order = Literal[\"asc\", \"desc\"]\n",
        "Op = Literal[\"eq\", \"neq\", \"lt\", \"lte\", \"gt\", \"gte\", \"ilike\", \"in\", \"is_null\", \"not_null\"]\n",
        "\n",
        "# -----------------------------\n",
        "# \"SQL\" schema (whitelist)\n",
        "# -----------------------------\n",
        "# Tables/columns from your DATA_CATALOG_FULL + INSIGHTS docs.\n",
        "SCHEMA: Dict[str, List[str]] = {\n",
        "    \"wko_branches\": [\n",
        "        \"id\", \"branche\", \"branch_url\", \"letter\", \"source\", \"discovered_at\", \"created_at\", \"updated_at\"\n",
        "    ],\n",
        "    \"wko_companies\": [\n",
        "        \"id\", \"wko_key\", \"branche\", \"name\", \"wko_detail_url\", \"company_website\", \"email\", \"phone\",\n",
        "        \"street\", \"zip_city\", \"address\", \"source_list_url\", \"crawled_at\", \"imported_at\",\n",
        "        \"search_text\", \"raw_row\", \"created_at\", \"updated_at\"\n",
        "    ],\n",
        "    \"projectfacts\": [\n",
        "        \"id\", \"pf_key\", \"name\", \"ort\", \"name_norm\", \"street\", \"plz\", \"city\", \"city_norm\", \"state\",\n",
        "        \"country\", \"segment_country\", \"industries\", \"size\", \"last_changed_at\", \"last_activity_at\",\n",
        "        \"company_address\", \"raw_addresses\", \"address_norm\", \"search_text\", \"raw_row\",\n",
        "        \"created_at\", \"updated_at\"\n",
        "    ],\n",
        "    \"evi_bilanz_publications\": [\n",
        "        \"id\", \"evi_key\", \"publication_date\", \"publication_type\", \"detail_url\", \"source_item_path\",\n",
        "        \"source_search_url\", \"company_name\", \"company_name_norm\", \"firmenbuchnummer\", \"search_text\",\n",
        "        \"crawled_at\", \"imported_at\", \"raw_row\", \"created_at\", \"updated_at\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "MAX_LIMIT = 50  # keep tool outputs small\n",
        "\n",
        "\n",
        "def _assert_table_col(table: str, cols: List[str]) -> None:\n",
        "    if table not in SCHEMA:\n",
        "        raise ValueError(f\"Unknown table: {table}. Allowed: {list(SCHEMA.keys())}\")\n",
        "    for c in cols:\n",
        "        if c != \"*\" and c not in SCHEMA[table]:\n",
        "            raise ValueError(f\"Unknown column '{c}' for table '{table}'\")\n",
        "\n",
        "\n",
        "def _apply_filters(q, table: str, where: Optional[List[Dict[str, Any]]]):\n",
        "    \"\"\"\n",
        "    where = [{\"col\":\"branche\",\"op\":\"eq\",\"val\":\"Abfallbehandler\"}, ...]\n",
        "    ops: eq, neq, lt, lte, gt, gte, ilike, in, is_null, not_null\n",
        "    \"\"\"\n",
        "    if not where:\n",
        "        return q\n",
        "    for f in where:\n",
        "        col = f[\"col\"]\n",
        "        op: Op = f[\"op\"]\n",
        "        val = f.get(\"val\")\n",
        "        _assert_table_col(table, [col])\n",
        "\n",
        "        if op == \"eq\":\n",
        "            q = q.eq(col, val)\n",
        "        elif op == \"neq\":\n",
        "            q = q.neq(col, val)\n",
        "        elif op == \"lt\":\n",
        "            q = q.lt(col, val)\n",
        "        elif op == \"lte\":\n",
        "            q = q.lte(col, val)\n",
        "        elif op == \"gt\":\n",
        "            q = q.gt(col, val)\n",
        "        elif op == \"gte\":\n",
        "            q = q.gte(col, val)\n",
        "        elif op == \"ilike\":\n",
        "            # PostgREST ilike expects a pattern, e.g. \"%foo%\"\n",
        "            q = q.ilike(col, val)\n",
        "        elif op == \"in\":\n",
        "            if not isinstance(val, list):\n",
        "                raise ValueError(\"op='in' expects val=list\")\n",
        "            q = q.in_(col, val)\n",
        "        elif op == \"is_null\":\n",
        "            q = q.is_(col, \"null\")\n",
        "        elif op == \"not_null\":\n",
        "            q = q.not_.is_(col, \"null\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported op: {op}\")\n",
        "    return q\n",
        "\n",
        "\n",
        "class GrablinDB:\n",
        "    def __init__(self, url: str, key: str):\n",
        "        self.sb = create_client(url, key)\n",
        "\n",
        "    # -----------------------------\n",
        "    # SQL-like tools\n",
        "    # -----------------------------\n",
        "    def sql_schema(self) -> dict:\n",
        "        \"\"\"Return allowed tables and columns (whitelist). Use to plan queries safely.\"\"\"\n",
        "        return {\"schema\": SCHEMA}\n",
        "\n",
        "    def sql_select(\n",
        "        self,\n",
        "        table: str,\n",
        "        cols: List[str],\n",
        "        where: Optional[List[Dict[str, Any]]] = None,\n",
        "        order_by: Optional[str] = None,\n",
        "        order: Order = \"desc\",\n",
        "        limit: int = 25,\n",
        "        offset: int = 0,\n",
        "    ) -> dict:\n",
        "        \"\"\"SQL SELECT over a single table with safe filters and pagination.\"\"\"\n",
        "        limit = min(int(limit), MAX_LIMIT)\n",
        "        offset = max(int(offset), 0)\n",
        "        _assert_table_col(table, cols)\n",
        "        if order_by:\n",
        "            _assert_table_col(table, [order_by])\n",
        "\n",
        "        select_str = \"*\" if cols == [\"*\"] else \",\".join(cols)\n",
        "        q = self.sb.table(table).select(select_str)\n",
        "\n",
        "        q = _apply_filters(q, table, where)\n",
        "\n",
        "        if order_by:\n",
        "            q = q.order(order_by, desc=(order == \"desc\"))\n",
        "\n",
        "        q = q.range(offset, offset + limit - 1)\n",
        "        res = q.execute()\n",
        "        rows = res.data or []\n",
        "        return {\"rows\": rows, \"count\": len(rows), \"table\": table, \"limit\": limit, \"offset\": offset}\n",
        "\n",
        "    def sql_distinct(\n",
        "        self,\n",
        "        table: str,\n",
        "        col: str,\n",
        "        where: Optional[List[Dict[str, Any]]] = None,\n",
        "        limit: int = 50,\n",
        "    ) -> dict:\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
